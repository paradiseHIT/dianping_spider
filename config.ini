[config]
# 是否使用cookie池，使用为True，反之为False，如果为True，则Cookie（下面这个参数）不被读取，在cookies.txt中配置所有cookie
use_cookie_pool = False
# cookie 如果为不需要cookie的任务则可不填，cookie相关的具体使用规则可以查看readme中碎碎念的有关cookie
Cookie: showNav=#nav-tab|0|0; navCtgScroll=0; navCtgScroll=210; fspop=test; _lxsdk_cuid=1906d7d9235c8-01b5855a9c67f2-19525637-13c680-1906d7d9235c8; _lxsdk=1906d7d9235c8-01b5855a9c67f2-19525637-13c680-1906d7d9235c8; _hc.v=5c5f83b0-747e-7a9e-61d8-06c6b7f8322b.1719823864; WEBDFPID=75255769zw96535v05w1w038wxv99wx78093w2wzx83979587v255zxv-2035183870863-1719823870863UKSSUYI75613c134b6a252faa6802015be905513550; s_ViewType=10; Hm_lvt_602b80cf8079ae6591966cc70a3940e7=1719823865,1719909174; qruuid=79569ebf-1337-4ec1-a998-7c9e1c5f7869; dper=0202641ff18431825eeddb554ebe1740b2e6d5cb5406b6fb6e4b954320df721a7203b6d8a4445318de1b14ec6c4100a5913817f209d8dd26b79d00000000fb200000ae8b309f0525d68466977d139774e3495fd15e10eae31f42cf74240d203f15b5d31d24c1d112c36dd2af02a73ac99c1e; ll=7fd06e815b796be3df069dec7836c3df; cy=3; cye=hangzhou; Hm_lpvt_602b80cf8079ae6591966cc70a3940e7=1720072676; _lxsdk_s=1907c25a033-37c-359-90c%7C%7C456
uuid : 5c5f83b0-747e-7a9e-61d8-06c6b7f8322b.1719823864
# tcv，获取方法详见文档，使用加密接口时使用
tcv = qo767wnn8n
# 默认user-agent,如果为None则为随机（仅可在不需要cookie的任务中使用,登录状态不建议随机user-agent）
user-agent = Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36
# 保存方式  暂时支持csv和mongo
save_mode = mongo
# mongodb 链接 （mongodb://servername:port，如果本地默认端口（27017）可不填）
mongo_path = mongodb://127.0.0.1:27017
# 累计请求多少次休息多少秒，从小到大排列。例：1,2;5,10 代表每请求1次休息2秒，每5次休息10秒。
requests_times = 1,5;3,10;10,50
[detail]
# 搜索关键字
keyword = 亲子
# 位置代号，如上海为1  北京为2 广州为4，暂时不支持地名自动转换id
location_id = 1
# 频道号
channel_id = 0
# 搜索页链接，用于非'http://www.dianping.com/search/keyword/(location_id)/(channel_id)_(key_word)/p(page_nub)的情况
# 如果不填，则默认填充上述url，填充后上述参数默认无效
# 注，填充的时候需要填充到p，例如：http://www.dianping.com/dalian/ch10/g110p2 填充http://www.dianping.com/dalian/ch10/g110p，从第几页开始则修改start_page
city=杭州
search_url = https://www.dianping.com/hangzhou/ch35/
#search_url = ""
groups = g32745
#groups = g32745,g2901,g2916,g2926,g20045,g2834,g50378,g50009,g50377,g50025,g50275,g50018,g50019,g5672,g27852,g20038,g32744,g138,g32747,g197,g50284,g33832
#groups = g2926,g20045,g2834,g50378,g50009,g50377,g50025,g50275,g50018,g50019,g5672,g27852,g20038,g32744,g138,g32747,g197,g50284,g33832
#起始页码
start_page = 34
# 是否只需要搜索页的首条内容
need_first = False
# 需要搜索的页数，最多50页
need_pages = 50
[proxy]
use_proxy = False
# ip 重复次数，由于非隧道模式时，一个ip常常有1分钟左右的有效时间，单次使用有点浪费，重复使用次数
repeat_nub = 5
# 代理模式为http提取
http_extract = True
# 代理模式为秘钥访问
key_extract = False
# http链接（秘钥模式不必填）
http_link = https://dps.kdlapi.com/api/getdps/?secret_id=oxtmkdnif7wsygd5lhpu&signature=kh9aumk68y539w9oznbyt55nvdqabzw7&num=1&pt=1&sep=1
# 代理服务器用户名和密码
# proxies = {
#     "http": "http://%(user)s:%(pwd)s@%(proxy)s/" % {"user": username, "pwd": password, "proxy": proxy_ip},
#     "https": "http://%(user)s:%(pwd)s@%(proxy)s/" % {"user": username, "pwd": password, "proxy": proxy_ip}
# }
username = 
password = 

# 代理服务器
proxy_host =
# 代理服务器端口
proxy_port =
# 秘钥id（http模式不必填）
key_id =
# 秘钥key（http模式不必填）
key_key =

